TP Kubernetes - Fonctionnalit√©s de D√©ploiement
3 exer cices pratiques - 20 minutes chacun
üéØ Objectifs du TP (60 minutes total)
Exer cice 1 (20min)  : Rollback de d√©ploiements
Exer cice 2 (20min)  : Autoscaling horizontal (HP A)
Exer cice 3 (20min)  : Jobs et CronJobs
Pr√©requis
Cluster Kubernetes fonctionnel
kubectl configur√©
Metrics Server install√©
‚ö† V√©rification rapide :
kubectl cluster-info && kubectl get nodes
Exer cice 1 - Rollback de D√©ploiements (20 minutes)
‚è± Dur√©e estim√©e : 20 minutes
Objectif
Apprendre √† g√©rer l'historique des d√©ploiements et ef fectuer des rollbacks en cas de probl√®me.
1. D√©ployer une application (5 min)
Cr√©ez webapp.yaml  :
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webapp
spec:
  replicas: 3
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app: webapp
  template:
    metadata:
      labels:
        app: webapp
    spec:
      containers:
      - name: nginx
        image: nginx:1.20
        ports:
        - containerPort: 80
        command: ["/bin/sh", "-c"]
        args: ["echo '<h1>Version 1.0</h1>' > /usr/share/nginx/html/index.html && nginx -g 'daemon off;'"]
---
apiVersion: v1
kind: Service
metadata:
  name: webapp-svc
spec:
  selector:
    app: webapp
  ports:
  - port: 80
    targetPort: 80
  type: ClusterIP
D√©ployez :
kubectl apply -f webapp.yaml --record
kubectl rollout status deployment/webapp
kubectl get pods -l app=webapp
2. Mettre √† jour avec une version d√©faillante (5 min)
Mettez √† jour vers une image qui n'existe pas :
kubectl set image deployment/webapp nginx=nginx:version-inexistante --record
kubectl rollout status deployment/webapp --timeout=60s
V√©rifiez l'√©tat :
kubectl get pods -l app=webapp
kubectl describe deployment webapp
3. Effectuer un rollback (5 min)
Consultez l'historique :
kubectl rollout history deployment/webapp
Effectuez le rollback :

kubectl rollout undo deployment/webapp
kubectl rollout status deployment/webapp
V√©rifiez le succ√®s :
kubectl get pods -l app=webapp
kubectl exec deployment/webapp -- curl -s localhost | grep Version
4. Test avanc√© - Rollback vers une r√©vision sp√©cifique (5 min)
Cr√©ez une nouvelle version :
kubectl patch deployment webapp -p '{"spec":{"template":{"spec":{"containers":[{"name":"nginx","command":["/bin/sh","-c"],"args":["ec
kubectl rollout status deployment/webapp
Rollback vers une r√©vision sp√©cifique :
kubectl rollout history deployment/webapp
kubectl rollout undo deployment/webapp --to-revision=1
kubectl rollout status deployment/webapp
‚úÖ Validation :  L'application doit af ficher "V ersion 1.0" apr√®s le rollback.
Exer cice 2 - Autoscaling Horizontal (HP A) (20 minutes)
‚è± Dur√©e estim√©e : 20 minutes
Objectif
Configurer l'autoscaling horizontal bas√© sur l'utilisation CPU et tester son fonctionnement.
1. D√©ployer une application de test (5 min)
Cr√©ez php-apache.yaml  :
apiVersion: apps/v1
kind: Deployment
metadata:
  name: php-apache
spec:
  selector:
    matchLabels:
      run: php-apache
  replicas: 1
  template:
    metadata:
      labels:
        run: php-apache
    spec:
      containers:
      - name: php-apache
        image: k8s.gcr.io/hpa-example
        ports:
        - containerPort: 80
        resources:
          limits:
            cpu: 500m
          requests:
            cpu: 200m
---
apiVersion: v1
kind: Service
metadata:
  name: php-apache
  labels:
    run: php-apache
spec:
  ports:
  - port: 80
  selector:
    run: php-apache
D√©ployez :
kubectl apply -f php-apache.yaml
kubectl get deployment php-apache
2. Cr√©er l'HPA (5 min)
Cr√©ez l'autoscaler :
kubectl autoscale deployment php-apache --cpu-percent=50 --min=1 --max=10
V√©rifiez l'√©tat :
kubectl get hpa
kubectl describe hpa php-apache
‚ö† Note :  L'HP A peut af ficher "unknown" au d√©but. Attendez quelques minutes pour que les m√©triques se stabilisent.
3. G√©n√©rer de la charge (7 min)
Dans un terminal, surveillez l'HP A :
kubectl get hpa php-apache --watch
Dans un autre terminal, cr√©ez une char ge :
kubectl run -i --tty load-generator --rm --image=busybox --restart=Never -- /bin/sh

# Dans le pod load-generator, ex√©cutez :
while true; do wget -q -O- http://php-apache; done
Observez l'√©volution :
kubectl get pods -l run=php-apache
kubectl top pods -l run=php-apache
4. Arr√™ter la charge et observer le scale-down (3 min)
Arr√™tez le pod load-generator (Ctrl+C puis exit).
Surveillez la r√©duction automatique :
kubectl get hpa php-apache --watch
kubectl get pods -l run=php-apache --watch
‚úÖ Validation :
L'HP A doit scaler jusqu'√† plusieurs pods sous char ge
Le scale-down doit se faire automatiquement apr√®s arr√™t de la char ge (5-10 min)
V√©rifiez avec kubectl describe hpa php-apache  les √©v√©nements de scaling
Exer cice 3 - Jobs et Cr onJobs (20 minutes)
‚è± Dur√©e estim√©e : 20 minutes
Objectif
Cr√©er et g√©rer des t√¢ches ponctuelles (Jobs) et planifi√©es (CronJobs) avec gestion des √©checs.
1. Job simple (5 min)
Cr√©ez simple-job.yaml  :
apiVersion: batch/v1
kind: Job
metadata:
  name: pi-calculation
spec:
  # Politique en cas d'√©chec
  backoffLimit: 3
  # D√©lai max d'ex√©cution
  activeDeadlineSeconds: 300
  template:
    spec:
      containers:
      - name: pi
        image: perl:5.34
        command: ["perl", "-Mbignum=bpi", "-wle", "print bpi(2000)"]
        resources:
          requests:
            memory: "64Mi"
            cpu: "100m"
          limits:
            memory: "128Mi"
            cpu: "200m"
      restartPolicy: Never
D√©ployez et surveillez :
kubectl apply -f simple-job.yaml
kubectl get jobs
kubectl logs job/pi-calculation
kubectl describe job pi-calculation
2. Job parall√®le avec gestion d'√©checs (7 min)
Cr√©ez parallel-job.yaml  :
apiVersion: batch/v1
kind: Job
metadata:
  name: data-processing
spec:
  parallelism: 3        # 3 pods en parall√®le
  completions: 6        # 6 t√¢ches √† compl√©ter au total
  backoffLimit: 2       # Max 2 tentatives en cas d'√©chec
  activeDeadlineSeconds: 180
  template:
    spec:
      containers:
      - name: worker
        image: busybox:1.35
        command: 
        - /bin/sh
        - -c
        - |
          echo "Worker $(hostname) d√©marr√© √† $(date)"
          # Simuler un traitement avec 20% de chance d'√©chec
          if [ $((RANDOM % 5)) -eq 0 ]; then
            echo "Erreur simul√©e dans $(hostname)"
            exit 1
          fi
          # Simuler du travail
          sleep $((10 + RANDOM % 20))
          echo "Worker $(hostname) termin√© avec succ√®s √† $(date)"
        resources:
          requests:
            memory: "32Mi"
            cpu: "50m"
      restartPolicy: Never

Testez le job parall√®le :
kubectl apply -f parallel-job.yaml
kubectl get jobs
kubectl get pods -l job-name=data-processing --watch
Analysez les r√©sultats :
kubectl describe job data-processing
kubectl logs -l job-name=data-processing
3. CronJob avec nettoyage automatique (8 min)
Cr√©ez backup-cronjob.yaml  :
apiVersion: batch/v1
kind: CronJob
metadata:
  name: database-backup
spec:
  schedule: "*/2 * * * *"  # Toutes les 2 minutes pour le test
  jobTemplate:
    spec:
      backoffLimit: 1
      activeDeadlineSeconds: 120
      template:
        spec:
          containers:
          - name: backup
            image: busybox:1.35
            command:
            - /bin/sh
            - -c
            - |
              echo "=== Backup d√©marr√© √† $(date) ==="
              echo "Hostname: $(hostname)"
            
              # Simuler une sauvegarde
              echo "Connexion √† la base de donn√©es..."
              sleep 5
              echo "Export des donn√©es..."
              sleep 10
              echo "Compression des fichiers..."
              sleep 5
            
              # Simuler parfois un √©chec (10% de chance)
              if [ $((RANDOM % 10)) -eq 0 ]; then
                echo "ERREUR: √âchec de la sauvegarde !"
                exit 1
              fi
            
              echo "=== Backup termin√© avec succ√®s √† $(date) ==="
            resources:
              requests:
                memory: "32Mi"
                cpu: "50m"
          restartPolicy: OnFailure
  # Conserver seulement les 3 derniers jobs r√©ussis
  successfulJobsHistoryLimit: 3
  # Conserver seulement le dernier job √©chou√©
  failedJobsHistoryLimit: 1
  # Politique de concurrence
  concurrencyPolicy: Forbid  # Emp√™cher les ex√©cutions simultan√©es
D√©ployez le CronJob :
kubectl apply -f backup-cronjob.yaml
kubectl get cronjobs
kubectl describe cronjob database-backup
Surveillez les ex√©cutions :
# Attendez quelques minutes et v√©rifiez
kubectl get jobs
kubectl get pods -l job-name
kubectl logs -l job-name --tail=20
Testez l'ex√©cution manuelle :
# Cr√©er un job manuellement depuis le CronJob
kubectl create job manual-backup --from=cronjob/database-backup
kubectl get jobs
kubectl logs job/manual-backup
‚úÖ Validation finale :
Le Job simple doit calculer PI et se terminer avec succ√®s
Le Job parall√®le doit ex√©cuter 6 t√¢ches avec 3 pods en parall√®le
Le CronJob doit s'ex√©cuter automatiquement toutes les 2 minutes
V√©rifiez avec kubectl get jobs,cronjobs
üéØ R√©capitulatif du TP
Ce que vous avez appris :
Rollback  : G√©rer l'historique et revenir √† une version stable
Autoscaling  : Adapter automatiquement le nombre de pods selon la char ge
Jobs/Cr onJobs  : Ex√©cuter des t√¢ches ponctuelles et planifi√©es
üßπ Nettoyage

kubectl delete deployments --all
kubectl delete services --all
kubectl delete hpa --all
kubectl delete jobs --all
kubectl delete cronjobs --all

