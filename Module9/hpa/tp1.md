# ğŸ”§ Lab Complet : Horizontal Pod Autoscaler (HPA) avec Kubernetes

## ğŸ¯ Objectif du Lab
Comprendre et configurer l'auto-scaling horizontal basÃ© sur l'utilisation CPU dans Kubernetes.

## ğŸ“š Concepts ClÃ©s

### Qu'est-ce que le HPA ?
Le **Horizontal Pod Autoscaler** ajuste automatiquement le nombre de pods dans un dÃ©ploiement en fonction de l'utilisation des ressources.

### Comment Ã§a marche ?
1. **Metrics Server** collecte les mÃ©triques de ressources
2. **HPA** surveille ces mÃ©triques
3. **Scaling** se dÃ©clenche quand les seuils sont dÃ©passÃ©s
4. **Controller Manager** ajuste les replicas

---

## ğŸš€ Phase 1 : Configuration Initiale

### 1.1 VÃ©rification de l'environnement
```bash
# VÃ©rifier que Kubernetes fonctionne
kubectl cluster-info

# VÃ©rifier les nodes
kubectl get nodes

# VÃ©rifier que Metrics Server est installÃ© (CRUCIAL)
kubectl top nodes
```
![alt text](image.png)

**ğŸ’¡ Commentaire :** Si `kubectl top nodes` ne fonctionne pas, il faut installer Metrics Server.

### 1.2 CrÃ©ation du fichier de dÃ©ploiement
```bash
# CrÃ©er le fichier hpa-demo.yaml
kubectl apply -f - <<EOF
apiVersion: apps/v1
kind: Deployment
metadata:
  name: hpa-demo
spec:
  replicas: 2
  selector:
    matchLabels:
      app: hpa-demo
  template:
    metadata:
      labels:
        app: hpa-demo
    spec:
      containers:
      - name: nginx
        image: nginx:latest
        ports:
        - containerPort: 80
        resources:
          requests:
            cpu: 100m
            memory: 64Mi
          limits:
            cpu: 200m
            memory: 128Mi
---
apiVersion: v1
kind: Service
metadata:
  name: hpa-demo-service
spec:
  selector:
    app: hpa-demo
  ports:
  - port: 80
    targetPort: 80
EOF
```

**ğŸ“ Explications :**
- **`resources.requests`** : Ressources rÃ©servÃ©es pour le pod
- **`resources.limits`** : Limites maximum pour le pod
- **`cpu: 100m`** = 0.1 core CPU
- La commande dans le container gÃ©nÃ¨re une charge CPU constante

---

## ğŸ›  Phase 2 : DÃ©ploiement de l'Application

### 2.1 DÃ©ploiement de l'application
```bash
# VÃ©rifier le dÃ©ploiement
kubectl get deployment hpa-demo

# VÃ©rifier les pods
kubectl get pods -l app=hpa-demo

# VÃ©rifier le service
kubectl get service hpa-demo-service
```
![alt text](image-6.png)

### 2.2 VÃ©rification des ressources
```bash
# Voir l'utilisation des ressources des pods
kubectl top pods -l app=hpa-demo

# DÃ©tails du dÃ©ploiement
kubectl describe deployment hpa-demo
```
**ğŸ” Observation attendue :**
![alt text](image-2.png)

![alt text](image-3.png)

---

## âš¡ Phase 3 : Configuration du HPA

### 3.1 CrÃ©ation du Horizontal Pod Autoscaler
```bash
# CrÃ©er le HPA avec des paramÃ¨tres spÃ©cifiques
kubectl autoscale deployment hpa-demo \
  --cpu-percent=50 \    # ğŸ”¹ Seuil de dÃ©clenchement Ã  50% CPU
  --min=2 \             # ğŸ”¹ Minimum de 2 pods
  --max=5 \             # ğŸ”¹ Maximum de 5 pods
  --name=hpa-demo       # ğŸ”¹ Nom du HPA
```

**ğŸ¯ ParamÃ¨tres du HPA :**
- **`--cpu-percent=50`** : Scaling dÃ©clenchÃ© Ã  50% d'utilisation CPU
- **`--min=2`** : Toujours au moins 2 pods actifs
- **`--max=5`** : Maximum 5 pods mÃªme sous forte charge

### 3.2 VÃ©rification du HPA
```bash
# Voir le HPA crÃ©Ã©
kubectl get hpa hpa-demo

# DÃ©tails complets du HPA
kubectl describe hpa hpa-demo
```

**ğŸ” RÃ©sultat attendu :**
![alt text](image-5.png)

**ğŸ“Š Lecture des colonnes :**
- **TARGETS** : `0%/50%` = utilisation actuelle / seuil de scaling
- **MINPODS/MAXPODS** : limites configurÃ©es
- **REPLICAS** : nombre actuel de pods

---

## ğŸ§ª Phase 4 : Test de Charge et Scaling

### 4.1 PrÃ©paration de l'observation
```bash
# Terminal 1 - Surveiller le HPA en temps rÃ©el
watch -n 2 "kubectl get hpa hpa-demo && echo '---' && kubectl top pods -l app=hpa-demo"

# Terminal 2 - Surveiller les pods
watch -n 2 "kubectl get pods -l app=hpa-demo | grep -v Terminating"
```

### 4.2 GÃ©nÃ©ration de charge CPU
** Scale manuel pour tester**
```bash
# Modifier le dÃ©ploiement pour augmenter la charge CPU
kubectl patch deployment hpa-demo -p '{"spec":{"template":{"spec":{"containers":[{"name":"nginx","command":["/bin/sh"],"args":["-c","while true; do sha256sum /dev/zero | head -c 1000000 > /dev/null; done"]}]}}}}'
```

### 4.3 Observation du scaling
**ğŸ“ˆ Comportement attendu :**

1. **Phase initiale** : 2 pods Ã  0-10% CPU
2. **Sous charge** : CPU dÃ©passe 50% â†’ scaling dÃ©clenchÃ©
3. **Scaling up** : Augmentation progressive des replicas
4. **Stabilisation** : HPA trouve l'Ã©quilibre autour de 50% CPU

**ğŸ” Commande de monitoring avancÃ©e :**
```bash
# Voir les Ã©vÃ©nements de scaling
kubectl get events --field-selector involvedObject.kind=HorizontalPodAutoscaler --sort-by=.lastTimestamp
```
![alt text](image-7.png)
---

## ğŸ“Š Phase 5 : Analyse des RÃ©sultats

### 5.1 Ã‰tat final du HPA
```bash
# Ã‰tat du HPA aprÃ¨s test
kubectl get hpa hpa-demo

# Historique des replicas
kubectl describe hpa hpa-demo | grep -A 10 "Events"
```

### 5.2 MÃ©triques dÃ©taillÃ©es
```bash
# Utilisation dÃ©taillÃ©e des ressources
kubectl top pods -l app=hpa-demo --use-protocol-buffers

# DÃ©tails des dÃ©cisions de scaling
kubectl describe hpa hpa-demo
```

---

## ğŸ§¹ Phase 6 : Nettoyage

### 6.1 Suppression des ressources
```bash
# Supprimer le HPA
kubectl delete hpa hpa-demo

# Supprimer le dÃ©ploiement et service
kubectl delete -f hpa-demo.yaml

# Supprimer le gÃ©nÃ©rateur de charge (si encore actif)
kubectl delete pod load-generator --ignore-not-found=true

# VÃ©rifier que tout est nettoyÃ©
kubectl get all -l app=hpa-demo
```

---

## ğŸ”§ PrÃ©requis et DÃ©pannage

### Installation de l'outil `hey` pour les tests de charge
```bash
# macOS
brew install hey

# Linux (Ubuntu/Debian)
sudo apt-get update && sudo apt-get install -y hey

# Windows (avec Chocolatey)
choco install hey
```

### Test avec `hey`
```bash
# Obtenir l'IP du service
SERVICE_IP=$(kubectl get service hpa-demo-service -o jsonpath='{.spec.clusterIP}')

# GÃ©nÃ©rer de la charge pendant 5 minutes
hey -z 300s -c 10 http://${SERVICE_IP}
```

---

## ğŸ“ Journal de Lab Typique

```
â±ï¸  T+0s     : DÃ©ploiement initial - 2 pods
â±ï¸  T+30s    : HPA crÃ©Ã© - cible 50% CPU
â±ï¸  T+1m     : DÃ©but charge - CPU Ã  15%
â±ï¸  T+2m     : CPU Ã  65% - scaling dÃ©clenchÃ©
â±ï¸  T+3m     : 3 pods - CPU Ã  45%
â±ï¸  T+4m     : CPU Ã  70% - scaling Ã  4 pods
â±ï¸  T+5m     : Stabilisation - 4 pods Ã  52% CPU
â±ï¸  T+10m    : ArrÃªt charge - scaling down progressif
```

---

## ğŸ“ Points ClÃ©s Ã  Retenir

1. **HPA nÃ©cessite Metrics Server** pour fonctionner
2. **Les resources requests/limits doivent Ãªtre dÃ©finies**
3. **Le scaling n'est pas instantanÃ©** (dÃ©lai de 15-30s)
4. **Le HPA utilise la moyenne d'utilisation** sur tous les pods
5. **Le period** Ã©vite le scaling trop agressif

Ce lab complet vous permet de maÃ®triser l'autoscaling horizontal dans Kubernetes ! ğŸš€